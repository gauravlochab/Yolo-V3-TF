{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO v3 Darknet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /Users/rahulkanojia/Documents/own/YOLO/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pylessons.com/YOLOv3-TF2-custrom-images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, InputSpec, Concatenate, LeakyReLU\n",
    "from tensorflow.keras.layers import Conv2D, Input, LeakyReLU, ZeroPadding2D, BatchNormalization, MaxPool2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "from Configs.mnist_config import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import BatchNormalization\n",
    "# BatchNormalization._USE_V2_BEHAVIOR = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "ANCHORS         = [[[10,  13], [16,   30], [33,   23]],\n",
    "                   [[30,  61], [62,   45], [59,  119]],\n",
    "                   [[116, 90], [156, 198], [373, 326]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     8,
     17,
     32,
     56,
     67,
     80,
     89,
     106
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Relu6(Layer):\n",
    "    def __init__(self):\n",
    "        super(self.__class__,self).__init__()\n",
    "        self.relu6 = tf.nn.relu6\n",
    "        \n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        return self.relu6(inputs)\n",
    "class BatchNorm(Layer):\n",
    "    def __init__(self, scale=True, center=True):\n",
    "        super(self.__class__,self).__init__()\n",
    "        #self.bn = tf.keras.layers.BatchNormalization(scale=scale, center=center, trainable=True)\n",
    "        self.bn = BatchNormalization(scale=scale, center=center, trainable=True)\n",
    "\n",
    "    #@tf.function\n",
    "    def call(self, inputs, training=True):\n",
    "        return self.bn(inputs, training=training)\n",
    "class Convolution2D(Layer):\n",
    "    def __init__(self, filters, kernel_size, is_activation = True, is_batch_norm = True, downsample=False):\n",
    "        super(self.__class__,self).__init__()\n",
    "        \n",
    "        self.downsample = downsample\n",
    "        if self.downsample:\n",
    "            padding = 'valid'\n",
    "            strides = 2\n",
    "        else:\n",
    "            strides = 1\n",
    "            padding = 'same'\n",
    "        \n",
    "        self.is_activation = is_activation\n",
    "        self.is_batch_norm = is_batch_norm\n",
    "        self.zero_pad =  ZeroPadding2D(((1, 0), (1, 0)))\n",
    "        self.conv = tf.keras.layers.Conv2D(filters = filters, kernel_size = kernel_size, strides = strides, padding=padding, \n",
    "                                           use_bias=not is_batch_norm, kernel_regularizer=l2(0.0005),\n",
    "                                           kernel_initializer=tf.random_normal_initializer(stddev=0.01),\n",
    "                                           bias_initializer=tf.constant_initializer(0.))\n",
    "        \n",
    "        self.bn = BatchNorm()\n",
    "        self.act = LeakyReLU(alpha=0.1)\n",
    "        \n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        \n",
    "        if self.downsample:\n",
    "            x = self.zero_pad(inputs)\n",
    "#             print(\" PAD SHAOE \",x.shape )\n",
    "            x = self.conv(x)\n",
    "        else:\n",
    "            x = self.conv(inputs)\n",
    "            \n",
    "        if self.is_batch_norm:\n",
    "            x = self.bn(x)\n",
    "        if self.is_activation:\n",
    "            x = self.act(x)\n",
    "        \n",
    "        return x\n",
    "class AveragePooling(Layer):\n",
    "    def __init__(self, pool_size):\n",
    "        super(self.__class__,self).__init__()\n",
    "        self.avgpool = tf.keras.layers.AveragePooling2D(pool_size=pool_size, padding=\"SAME\")\n",
    "        \n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        \n",
    "        x = self.avgpool(inputs)\n",
    "         \n",
    "        return x\n",
    "class DenseLayer(Layer):\n",
    "    def __init__(self, units):\n",
    "        super(self.__class__,self).__init__()\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(units=units,\n",
    "                                           kernel_initializer=tf.random_normal_initializer(stddev=0.01))\n",
    "        \n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        \n",
    "        x = self.dense(inputs)\n",
    "        \n",
    "        return x\n",
    "class FlattenLayer(Layer):\n",
    "    def __init__(self):\n",
    "        super(self.__class__,self).__init__()\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        \n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        x = self.flatten(inputs)\n",
    "        return x\n",
    "class Residual_Block(Layer):\n",
    "    def __init__(self, filters):\n",
    "        super(self.__class__,self).__init__()\n",
    "        self.conv1  = Convolution2D(filters =   filters, kernel_size = (1, 1))\n",
    "        self.conv2  = Convolution2D(filters = 2*filters, kernel_size = (3, 3))\n",
    "        self.add = tf.keras.layers.Add()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        short_cut = inputs\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.conv2(x)\n",
    "        \n",
    "#         print(\" Residual Output 1\", short_cut.shape, x.shape)\n",
    "        residual_output = self.add([short_cut,x])\n",
    "#         print(\" Residual Output 2\", residual_output.shape)\n",
    "    \n",
    "        return residual_output\n",
    "class Upsample(Layer):\n",
    "    def __init__(self):\n",
    "        super(self.__class__,self).__init__()\n",
    "        \n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        return tf.image.resize(inputs, (inputs.shape[1] * 2, inputs.shape[2] * 2), method='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class Darknet(Model):\n",
    "    def __init__(self):\n",
    "        super(self.__class__,self).__init__()\n",
    "        self.conv1        = Convolution2D(32, (3, 3), is_activation=True, is_batch_norm=True, downsample=False)\n",
    "        self.conv2        = Convolution2D(64, (3, 3), is_activation=True, is_batch_norm=True, downsample=True)\n",
    "        \n",
    "        self.residual1_1  = Residual_Block(32)\n",
    "        \n",
    "        self.conv3        = Convolution2D(128, (3, 3), is_activation=True, is_batch_norm=True, downsample=True)\n",
    "        \n",
    "        self.residual2_1  = Residual_Block(64)\n",
    "        self.residual2_2  = Residual_Block(64)\n",
    "        \n",
    "        self.conv4        = Convolution2D(256, (3, 3),is_activation=True, is_batch_norm=True, downsample=True)\n",
    "        \n",
    "        self.residual3_1  = Residual_Block(128)\n",
    "        self.residual3_2  = Residual_Block(128)\n",
    "        self.residual3_3  = Residual_Block(128)\n",
    "        self.residual3_4  = Residual_Block(128)\n",
    "        self.residual3_5  = Residual_Block(128)\n",
    "        self.residual3_6  = Residual_Block(128)\n",
    "        self.residual3_7  = Residual_Block(128)\n",
    "        self.residual3_8  = Residual_Block(128)\n",
    "        \n",
    "        self.conv5        = Convolution2D(512,  (3, 3),is_activation=True, is_batch_norm=True, downsample=True)\n",
    "        \n",
    "        self.residual4_1  = Residual_Block(256)\n",
    "        self.residual4_2  = Residual_Block(256)\n",
    "        self.residual4_3  = Residual_Block(256)\n",
    "        self.residual4_4  = Residual_Block(256)\n",
    "        self.residual4_5  = Residual_Block(256)\n",
    "        self.residual4_6  = Residual_Block(256)\n",
    "        self.residual4_7  = Residual_Block(256)\n",
    "        self.residual4_8  = Residual_Block(256)\n",
    "        \n",
    "        self.conv6        = Convolution2D(1024, (3, 3),is_activation=True, is_batch_norm=True, downsample=True)\n",
    "        \n",
    "        self.residual5_1  = Residual_Block(512)\n",
    "        self.residual5_2  = Residual_Block(512)\n",
    "        self.residual5_3  = Residual_Block(512)\n",
    "        self.residual5_4  = Residual_Block(512)\n",
    "             \n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.conv2(x) \n",
    "        \n",
    "        x = self.residual1_1(x)        \n",
    "        \n",
    "        x = self.conv3(x) \n",
    "        x = self.residual2_1(x)\n",
    "        x = self.residual2_2(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x = self.residual3_1(x)\n",
    "        x = self.residual3_2(x)\n",
    "        x = self.residual3_3(x)\n",
    "        x = self.residual3_4(x)\n",
    "        x = self.residual3_5(x)\n",
    "        x = self.residual3_6(x)\n",
    "        x = self.residual3_7(x)\n",
    "        x = self.residual3_8(x)\n",
    "        route1 = x\n",
    "        \n",
    "        x = self.conv5(x)\n",
    "        x = self.residual4_1(x)\n",
    "        x = self.residual4_2(x)\n",
    "        x = self.residual4_3(x)\n",
    "        x = self.residual4_4(x)\n",
    "        x = self.residual4_5(x)\n",
    "        x = self.residual4_6(x)\n",
    "        x = self.residual4_7(x)\n",
    "        x = self.residual4_8(x)\n",
    "        route2 = x\n",
    "        \n",
    "        x = self.conv6(x)\n",
    "        x = self.residual5_1(x)\n",
    "        x = self.residual5_2(x)\n",
    "        x = self.residual5_3(x)\n",
    "        x = self.residual5_4(x)\n",
    "        \n",
    "    \n",
    "        return route1, route2, x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     43
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class YOLOV3(Model):\n",
    "    def __init__(self, NUM_CLASS, TRAIN = False):\n",
    "        super(self.__class__,self).__init__()\n",
    "        self.NUM_CLASS = NUM_CLASS\n",
    "        self.TRAIN = TRAIN\n",
    "        self.darknet = Darknet()\n",
    "        self.conv1 = Convolution2D(512,  (1, 1), is_activation=True, is_batch_norm=True, downsample=False)\n",
    "        self.conv2 = Convolution2D(1024, (3, 3), is_activation=True, is_batch_norm=True, downsample=False)\n",
    "        self.conv3 = Convolution2D(512,  (1, 1), is_activation=True, is_batch_norm=True, downsample=False)\n",
    "        self.conv4 = Convolution2D(1024, (3, 3), is_activation=True, is_batch_norm=True, downsample=False)\n",
    "        self.conv5 = Convolution2D(512,  (1, 1), is_activation=True, is_batch_norm=True, downsample=False)\n",
    "        \n",
    "        self.conv_lobj_branch = Convolution2D(1024, (3, 3), is_activation=True, is_batch_norm=True, downsample=False)\n",
    "        self.conv_lbbox = Convolution2D(3*(NUM_CLASS + 5),  (1, 1), is_activation=False, is_batch_norm=False, downsample=False)\n",
    "        \n",
    "        self.conv6 = Convolution2D(256,  (1, 1), is_activation=True, is_batch_norm=True, downsample=False)\n",
    "        self.upsample1 = Upsample()\n",
    "         \n",
    "        self.conv7  = Convolution2D(256, (1, 1), is_activation=True, is_batch_norm=True, downsample=False)\n",
    "        self.conv8  = Convolution2D(512, (3, 3), is_activation=True, is_batch_norm=True, downsample=False)\n",
    "        self.conv9  = Convolution2D(256, (1, 1), is_activation=True, is_batch_norm=True, downsample=False)\n",
    "        self.conv10 = Convolution2D(512, (3, 3), is_activation=True, is_batch_norm=True, downsample=False)\n",
    "        self.conv11 = Convolution2D(256, (1, 1), is_activation=True, is_batch_norm=True, downsample=False)\n",
    "        \n",
    "        \n",
    "        self.conv_mobj_branch = Convolution2D(512, (3, 3), is_activation=True, is_batch_norm=True, downsample=False)\n",
    "        self.conv_mbbox = Convolution2D(3*(NUM_CLASS + 5), (1, 1), is_activation=False, is_batch_norm=False, downsample=False)\n",
    "        #convolutional(conv_mobj_branch, (1, 1, 512, 3*(NUM_CLASS + 5)), activate=False, bn=False)\n",
    "\n",
    "        \n",
    "        self.conv12 = Convolution2D(128, (1, 1), is_activation=True, is_batch_norm=True, downsample=False)\n",
    "        self.upsample2  = Upsample()\n",
    "        self.conv13 = Convolution2D(128, (1, 1), is_activation=True, is_batch_norm=True, downsample=False)\n",
    "        self.conv14 = Convolution2D(256, (3, 3), is_activation=True, is_batch_norm=True, downsample=False)\n",
    "        self.conv15 = Convolution2D(128, (1, 1), is_activation=True, is_batch_norm=True, downsample=False)\n",
    "        self.conv16 = Convolution2D(256, (3, 3), is_activation=True, is_batch_norm=True, downsample=False)\n",
    "        self.conv17 = Convolution2D(128, (1, 1), is_activation=True, is_batch_norm=True, downsample=False)    \n",
    "\n",
    "        self.conv_sobj_branch = Convolution2D(256, (3, 3), is_activation=True, is_batch_norm=True, downsample=False)\n",
    "    # conv_sbbox is used to predict small size objects, shape = [None, 52, 52, 255]\n",
    "        self.conv_sbbox = Convolution2D(3*(NUM_CLASS +5), (1, 1), is_activation=False, is_batch_norm=False, downsample=False)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs, training=True):\n",
    "        \n",
    "        route_1, route_2, conv  = self.darknet(inputs)    \n",
    "        x = self.conv1(conv)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        conv_lobj_branch = self.conv_lobj_branch(x)\n",
    "        conv_lbbox = self.conv_lbbox(conv_lobj_branch)\n",
    "        \n",
    "        x = self.conv6(x)\n",
    "        x = self.upsample1(x)\n",
    "        \n",
    "        x = tf.concat([x, route_2], axis=-1)\n",
    "        x = self.conv7(x)\n",
    "        x = self.conv8(x)\n",
    "        x = self.conv9(x)\n",
    "        x = self.conv10(x)\n",
    "        x = self.conv11(x)\n",
    "        \n",
    "        conv_mobj_branch = self.conv_mobj_branch(x)\n",
    "        conv_mbbox = self.conv_mbbox(conv_mobj_branch)\n",
    "        \n",
    "        x = self.conv12(x)\n",
    "        x = self.upsample2(x)\n",
    "        x = tf.concat([x, route_1], axis=-1)\n",
    "        x = self.conv13(x)\n",
    "        x = self.conv14(x)\n",
    "        x = self.conv15(x)\n",
    "        x = self.conv16(x)\n",
    "        x = self.conv17(x)\n",
    "        conv_sobj_branch = self.conv_sobj_branch(x)\n",
    "        conv_sbbox = self.conv_sbbox(conv_sobj_branch)\n",
    "        \n",
    "        conv_tensors = [conv_sbbox, conv_mbbox, conv_lbbox]\n",
    "        \n",
    "        output_tensors = []\n",
    "\n",
    "        for i, conv_tensor in enumerate(conv_tensors):\n",
    "            pred_tensor = decode(conv_tensor, self.NUM_CLASS, i)\n",
    "            if self.TRAIN:\n",
    "                output_tensors.append(conv_tensor)\n",
    "            output_tensors.append(pred_tensor)\n",
    "        \n",
    "        return output_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "yolo = YOLOV3(10, TRAIN=True)\n",
    "tert = np.random.rand(1,416,416,3).astype(np.float32)\n",
    "bert = yolo(tert, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bert[0].shape, bert[1].shape, bert[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Loading weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# W1 = yolo.weights\n",
    "# W2 = mine.weights\n",
    "# for i in range(len(WW)):\n",
    "# #     if WW[i].shape!=W2[i].shape or WW[i].name.split('/')[-1].split(':')[0] != W2[i].name.split('/')[-1].split(':')[0]:\n",
    "#     print(\"Index :\",i, \" \",WW[i].shape, W2[i].shape, WW[i].shape==W2[i].shape,\" || \",WW[i].name.split('/')[-1].split(':')[0] == W2[i].name.split('/')[-1].split(':')[0])\n",
    "# for i in range(len(WW)):\n",
    "# #     if WW[i].shape!=W2[i].shape or WW[i].name.split('/')[-1].split(':')[0] != W2[i].name.split('/')[-1].split(':')[0]:\n",
    "#     print(\"Index :\",i, \" \",WW[i].shape, W2[i].shape, WW[i].shape==W2[i].shape,\" || \",WW[i].name.split('/')[-1].split(':')[0] == W2[i].name.split('/')[-1].split(':')[0])\n",
    "# for i in range(len(WW),len(W2)):\n",
    "#     WW.append(W2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ### Loading Weights\n",
    "# WW = []\n",
    "# i = 0\n",
    "# while(i<13):\n",
    "#     WW.append(yolo.weights[i])\n",
    "#     i += 1  \n",
    "# WW.append(yolo.weights[15])\n",
    "# WW.append(yolo.weights[16])\n",
    "# WW.append(yolo.weights[17])\n",
    "# WW.append(yolo.weights[13])\n",
    "# WW.append(yolo.weights[14])\n",
    "# i = 18\n",
    "# while(i<28):\n",
    "#     WW.append(yolo.weights[i])\n",
    "#     i += 1\n",
    "# while(i<43):\n",
    "    \n",
    "#     if i==33 :\n",
    "#         for _ in range(5):\n",
    "#             WW.append(yolo.weights[i])\n",
    "#             i += 1\n",
    "    \n",
    "#     WW.append(yolo.weights[i+2])\n",
    "#     WW.append(yolo.weights[i+3])\n",
    "#     WW.append(yolo.weights[i+4])\n",
    "#     WW.append(yolo.weights[i])\n",
    "#     WW.append(yolo.weights[i+1])\n",
    "#     i += 5\n",
    "# while(i<53):\n",
    "#     WW.append(yolo.weights[i])\n",
    "#     i += 1\n",
    "# WW.append(yolo.weights[55])\n",
    "# WW.append(yolo.weights[56])\n",
    "# WW.append(yolo.weights[57])\n",
    "# WW.append(yolo.weights[53])\n",
    "# WW.append(yolo.weights[54])\n",
    "# i = 58\n",
    "# while(i<128):\n",
    "#     for _ in range(5):\n",
    "#         WW.append(yolo.weights[i])\n",
    "#         i += 1\n",
    "#     WW.append(yolo.weights[i+2])\n",
    "#     WW.append(yolo.weights[i+3])\n",
    "#     WW.append(yolo.weights[i+4])\n",
    "#     WW.append(yolo.weights[i])\n",
    "#     WW.append(yolo.weights[i+1])\n",
    "#     i+=5\n",
    "# while(i<138):\n",
    "#     WW.append(yolo.weights[i])\n",
    "#     i += 1    \n",
    "# while(i<213):\n",
    "#     WW.append(yolo.weights[i+2])\n",
    "#     WW.append(yolo.weights[i+3])\n",
    "#     WW.append(yolo.weights[i+4])\n",
    "#     WW.append(yolo.weights[i])\n",
    "#     WW.append(yolo.weights[i+1])\n",
    "#     i+=5\n",
    "#     for _ in range(5):\n",
    "#         WW.append(yolo.weights[i])\n",
    "#         i += 1\n",
    "# for _ in range(5):\n",
    "#     WW.append(yolo.weights[i])\n",
    "#     i += 1\n",
    "# while(i<258):\n",
    "#     WW.append(yolo.weights[i+2])\n",
    "#     WW.append(yolo.weights[i+3])\n",
    "#     WW.append(yolo.weights[i+4])\n",
    "#     WW.append(yolo.weights[i])\n",
    "#     WW.append(yolo.weights[i+1])\n",
    "#     i+=5\n",
    "#     for _ in range(5):\n",
    "#         WW.append(yolo.weights[i])\n",
    "#         i += 1\n",
    "# for _ in range(22):\n",
    "#     WW.append(yolo.weights[i])\n",
    "#     i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "file = open('../Darknet_weights.pkl', 'rb')\n",
    "data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(len(W1), len(data))\n",
    "W1 = yolo.weights\n",
    "for i in range(len(data), len(W1)):\n",
    "    data.append(W1[i])\n",
    "print(len(W1), len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "new_data = []\n",
    "for i in data:\n",
    "    new_data.append(i.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "yolo.set_weights(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /Users/rahulkanojia/Documents/own/YOLO/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python Dataset/MNIST/make_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# from yolov3.dataset import Dataset\n",
    "from Dataset.MNIST.mnist_data import Dataset\n",
    "trainset = Dataset('train')\n",
    "testset = Dataset('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, target in trainset:\n",
    "    print(image.shape, len(target))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     36,
     53,
     60,
     96,
     121,
     169
    ]
   },
   "outputs": [],
   "source": [
    "def decode(conv_output, NUM_CLASS, i=0):\n",
    "    # where i = 0, 1 or 2 to correspond to the three grid scales  \n",
    "    conv_shape       = tf.shape(conv_output)\n",
    "    batch_size       = conv_shape[0]\n",
    "    output_size      = conv_shape[1]\n",
    "\n",
    "    conv_output = tf.reshape(conv_output, (batch_size, output_size, output_size, 3, 5 + NUM_CLASS))\n",
    "\n",
    "    conv_raw_dxdy = conv_output[:, :, :, :, 0:2] # offset of center position     \n",
    "    conv_raw_dwdh = conv_output[:, :, :, :, 2:4] # Prediction box length and width offset\n",
    "    conv_raw_conf = conv_output[:, :, :, :, 4:5] # confidence of the prediction box\n",
    "    conv_raw_prob = conv_output[:, :, :, :, 5: ] # category probability of the prediction box \n",
    "\n",
    "    # next need Draw the grid. Where output_size is equal to 13, 26 or 52  \n",
    "    y = tf.range(output_size, dtype=tf.int32)\n",
    "    y = tf.expand_dims(y, -1)\n",
    "    y = tf.tile(y, [1, output_size])\n",
    "    x = tf.range(output_size,dtype=tf.int32)\n",
    "    x = tf.expand_dims(x, 0)\n",
    "    x = tf.tile(x, [output_size, 1])\n",
    "\n",
    "    xy_grid = tf.concat([x[:, :, tf.newaxis], y[:, :, tf.newaxis]], axis=-1)\n",
    "    xy_grid = tf.tile(xy_grid[tf.newaxis, :, :, tf.newaxis, :], [batch_size, 1, 1, 3, 1])\n",
    "    xy_grid = tf.cast(xy_grid, tf.float32)\n",
    "\n",
    "    # Calculate the center position of the prediction box:\n",
    "    pred_xy = (tf.sigmoid(conv_raw_dxdy) + xy_grid) * STRIDES[i]\n",
    "    # Calculate the length and width of the prediction box:\n",
    "    pred_wh = (tf.exp(conv_raw_dwdh) * ANCHORS[i]) * STRIDES[i]\n",
    "\n",
    "    pred_xywh = tf.concat([pred_xy, pred_wh], axis=-1)\n",
    "    pred_conf = tf.sigmoid(conv_raw_conf) # object box calculates the predicted confidence\n",
    "    pred_prob = tf.sigmoid(conv_raw_prob) # calculating the predicted probability category box object\n",
    "\n",
    "    # calculating the predicted probability category box object\n",
    "    return tf.concat([pred_xywh, pred_conf, pred_prob], axis=-1)\n",
    "def bbox_iou(boxes1, boxes2):\n",
    "    boxes1_area = boxes1[..., 2] * boxes1[..., 3]\n",
    "    boxes2_area = boxes2[..., 2] * boxes2[..., 3]\n",
    "\n",
    "    boxes1 = tf.concat([boxes1[..., :2] - boxes1[..., 2:] * 0.5,\n",
    "                        boxes1[..., :2] + boxes1[..., 2:] * 0.5], axis=-1)\n",
    "    boxes2 = tf.concat([boxes2[..., :2] - boxes2[..., 2:] * 0.5,\n",
    "                        boxes2[..., :2] + boxes2[..., 2:] * 0.5], axis=-1)\n",
    "\n",
    "    left_up = tf.maximum(boxes1[..., :2], boxes2[..., :2])\n",
    "    right_down = tf.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
    "\n",
    "    inter_section = tf.maximum(right_down - left_up, 0.0)\n",
    "    inter_area = inter_section[..., 0] * inter_section[..., 1]\n",
    "    union_area = boxes1_area + boxes2_area - inter_area\n",
    "\n",
    "    return 1.0 * inter_area / union_area\n",
    "def read_class_names(class_file_name):\n",
    "    # loads class name from a file\n",
    "    names = {}\n",
    "    with open(class_file_name, 'r') as data:\n",
    "        for ID, name in enumerate(data):\n",
    "            names[ID] = name.strip('\\n')\n",
    "    return names\n",
    "def bbox_giou(boxes1, boxes2):\n",
    "    boxes1 = tf.concat([boxes1[..., :2] - boxes1[..., 2:] * 0.5,\n",
    "                        boxes1[..., :2] + boxes1[..., 2:] * 0.5], axis=-1)\n",
    "    boxes2 = tf.concat([boxes2[..., :2] - boxes2[..., 2:] * 0.5,\n",
    "                        boxes2[..., :2] + boxes2[..., 2:] * 0.5], axis=-1)\n",
    "\n",
    "    boxes1 = tf.concat([tf.minimum(boxes1[..., :2], boxes1[..., 2:]),\n",
    "                        tf.maximum(boxes1[..., :2], boxes1[..., 2:])], axis=-1)\n",
    "    boxes2 = tf.concat([tf.minimum(boxes2[..., :2], boxes2[..., 2:]),\n",
    "                        tf.maximum(boxes2[..., :2], boxes2[..., 2:])], axis=-1)\n",
    "\n",
    "    boxes1_area = (boxes1[..., 2] - boxes1[..., 0]) * (boxes1[..., 3] - boxes1[..., 1])\n",
    "    boxes2_area = (boxes2[..., 2] - boxes2[..., 0]) * (boxes2[..., 3] - boxes2[..., 1])\n",
    "\n",
    "    left_up = tf.maximum(boxes1[..., :2], boxes2[..., :2])\n",
    "    right_down = tf.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
    "\n",
    "    inter_section = tf.maximum(right_down - left_up, 0.0)\n",
    "    inter_area = inter_section[..., 0] * inter_section[..., 1]\n",
    "    union_area = boxes1_area + boxes2_area - inter_area\n",
    "\n",
    "    # Calculate the iou value between the two bounding boxes\n",
    "    iou = inter_area / union_area\n",
    "\n",
    "    # Calculate the coordinates of the upper left corner and the lower right corner of the smallest closed convex surface\n",
    "    enclose_left_up = tf.minimum(boxes1[..., :2], boxes2[..., :2])\n",
    "    enclose_right_down = tf.maximum(boxes1[..., 2:], boxes2[..., 2:])\n",
    "    enclose = tf.maximum(enclose_right_down - enclose_left_up, 0.0)\n",
    "\n",
    "    # Calculate the area of the smallest closed convex surface C\n",
    "    enclose_area = enclose[..., 0] * enclose[..., 1]\n",
    "\n",
    "    # Calculate the GIoU value according to the GioU formula  \n",
    "    giou = iou - 1.0 * (enclose_area - union_area) / enclose_area\n",
    "\n",
    "    return giou\n",
    "def bbox_ciou(boxes1, boxes2):\n",
    "    boxes1_coor = tf.concat([boxes1[..., :2] - boxes1[..., 2:] * 0.5,\n",
    "                        boxes1[..., :2] + boxes1[..., 2:] * 0.5], axis=-1)\n",
    "    boxes2_coor = tf.concat([boxes2[..., :2] - boxes2[..., 2:] * 0.5,\n",
    "                        boxes2[..., :2] + boxes2[..., 2:] * 0.5], axis=-1)\n",
    "\n",
    "    left = tf.maximum(boxes1_coor[..., 0], boxes2_coor[..., 0])\n",
    "    up = tf.maximum(boxes1_coor[..., 1], boxes2_coor[..., 1])\n",
    "    right = tf.maximum(boxes1_coor[..., 2], boxes2_coor[..., 2])\n",
    "    down = tf.maximum(boxes1_coor[..., 3], boxes2_coor[..., 3])\n",
    "\n",
    "    c = (right - left) * (right - left) + (up - down) * (up - down)\n",
    "    iou = bbox_iou(boxes1, boxes2)\n",
    "\n",
    "    u = (boxes1[..., 0] - boxes2[..., 0]) * (boxes1[..., 0] - boxes2[..., 0]) + (boxes1[..., 1] - boxes2[..., 1]) * (boxes1[..., 1] - boxes2[..., 1])\n",
    "    d = u / c\n",
    "\n",
    "    ar_gt = boxes2[..., 2] / boxes2[..., 3]\n",
    "    ar_pred = boxes1[..., 2] / boxes1[..., 3]\n",
    "\n",
    "    ar_loss = 4 / (np.pi * np.pi) * (tf.atan(ar_gt) - tf.atan(ar_pred)) * (tf.atan(ar_gt) - tf.atan(ar_pred))\n",
    "    alpha = ar_loss / (1 - iou + ar_loss + 0.000001)\n",
    "    ciou_term = d + alpha * ar_loss\n",
    "\n",
    "    return iou - ciou_term\n",
    "def compute_loss(pred, conv, label, bboxes, i=0, CLASSES=YOLO_COCO_CLASSES):\n",
    "    NUM_CLASS = len(read_class_names(CLASSES))\n",
    "    conv_shape  = tf.shape(conv)\n",
    "    batch_size  = conv_shape[0]\n",
    "    output_size = conv_shape[1]\n",
    "    input_size  = STRIDES[i] * output_size\n",
    "    conv = tf.reshape(conv, (batch_size, output_size, output_size, 3, 5 + NUM_CLASS))\n",
    "\n",
    "    conv_raw_conf = conv[:, :, :, :, 4:5]\n",
    "    conv_raw_prob = conv[:, :, :, :, 5:]\n",
    "\n",
    "    pred_xywh     = pred[:, :, :, :, 0:4]\n",
    "    pred_conf     = pred[:, :, :, :, 4:5]\n",
    "\n",
    "    label_xywh    = label[:, :, :, :, 0:4]\n",
    "    respond_bbox  = label[:, :, :, :, 4:5]\n",
    "    label_prob    = label[:, :, :, :, 5:]\n",
    "\n",
    "    giou = tf.expand_dims(bbox_giou(pred_xywh, label_xywh), axis=-1)\n",
    "    input_size = tf.cast(input_size, tf.float32)\n",
    "\n",
    "    bbox_loss_scale = 2.0 - 1.0 * label_xywh[:, :, :, :, 2:3] * label_xywh[:, :, :, :, 3:4] / (input_size ** 2)\n",
    "    giou_loss = respond_bbox * bbox_loss_scale * (1 - giou)\n",
    "\n",
    "    iou = bbox_iou(pred_xywh[:, :, :, :, np.newaxis, :], bboxes[:, np.newaxis, np.newaxis, np.newaxis, :, :])\n",
    "    # Find the value of IoU with the real box The largest prediction box\n",
    "    max_iou = tf.expand_dims(tf.reduce_max(iou, axis=-1), axis=-1)\n",
    "\n",
    "    # If the largest iou is less than the threshold, it is considered that the prediction box contains no objects, then the background box\n",
    "    respond_bgd = (1.0 - respond_bbox) * tf.cast( max_iou < YOLO_IOU_LOSS_THRESH, tf.float32 )\n",
    "\n",
    "    conf_focal = tf.pow(respond_bbox - pred_conf, 2)\n",
    "\n",
    "    # Calculate the loss of confidence\n",
    "    # we hope that if the grid contains objects, then the network output prediction box has a confidence of 1 and 0 when there is no object.\n",
    "    conf_loss = conf_focal * (\n",
    "            respond_bbox * tf.nn.sigmoid_cross_entropy_with_logits(labels=respond_bbox, logits=conv_raw_conf)\n",
    "            +\n",
    "            respond_bgd * tf.nn.sigmoid_cross_entropy_with_logits(labels=respond_bbox, logits=conv_raw_conf)\n",
    "    )\n",
    "\n",
    "    prob_loss = respond_bbox * tf.nn.sigmoid_cross_entropy_with_logits(labels=label_prob, logits=conv_raw_prob)\n",
    "\n",
    "    giou_loss = tf.reduce_mean(tf.reduce_sum(giou_loss, axis=[1,2,3,4]))\n",
    "    conf_loss = tf.reduce_mean(tf.reduce_sum(conf_loss, axis=[1,2,3,4]))\n",
    "    prob_loss = tf.reduce_mean(tf.reduce_sum(prob_loss, axis=[1,2,3,4]))\n",
    "\n",
    "    return giou_loss, conf_loss, prob_loss\n",
    "def read_class_names(class_file_name):\n",
    "    # loads class name from a file\n",
    "    names = {}\n",
    "    with open(class_file_name, 'r') as data:\n",
    "        for ID, name in enumerate(data):\n",
    "            names[ID] = name.strip('\\n')\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = len(trainset)\n",
    "global_steps = tf.Variable(1, trainable=False, dtype=tf.int64)\n",
    "warmup_steps = TRAIN_WARMUP_EPOCHS * steps_per_epoch\n",
    "total_steps = TRAIN_EPOCHS * steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     4
    ]
   },
   "outputs": [],
   "source": [
    "if os.path.exists(TRAIN_LOGDIR): shutil.rmtree(TRAIN_LOGDIR)\n",
    "writer = tf.summary.create_file_writer(TRAIN_LOGDIR)\n",
    "\n",
    "validate_writer = tf.summary.create_file_writer(TRAIN_LOGDIR)\n",
    "def validate_step(image_data, target):\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred_result = yolo(image_data, training=False)\n",
    "        giou_loss=conf_loss=prob_loss=0\n",
    "\n",
    "        # optimizing process\n",
    "        grid = 3 if not TRAIN_YOLO_TINY else 2\n",
    "        for i in range(grid):\n",
    "            conv, pred = pred_result[i*2], pred_result[i*2+1]\n",
    "            \n",
    "            loss_items = compute_loss(pred, conv, *target[i], i, CLASSES=TRAIN_CLASSES)\n",
    "            giou_loss += loss_items[0]\n",
    "            conf_loss += loss_items[1]\n",
    "            prob_loss += loss_items[2]\n",
    "\n",
    "        total_loss = giou_loss + conf_loss + prob_loss\n",
    "\n",
    "    return giou_loss.numpy(), conf_loss.numpy(), prob_loss.numpy(), total_loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "def train_step(image_data, target):\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred_result = yolo(image_data, training=True)\n",
    "        giou_loss=conf_loss=prob_loss=0\n",
    "\n",
    "        # optimizing process\n",
    "        grid = 3 if not TRAIN_YOLO_TINY else 2\n",
    "        for i in range(grid):\n",
    "            conv, pred = pred_result[i*2], pred_result[i*2+1]\n",
    "            loss_items = compute_loss(pred, conv, *target[i], i, CLASSES=TRAIN_CLASSES)\n",
    "            giou_loss += loss_items[0]\n",
    "            conf_loss += loss_items[1]\n",
    "            prob_loss += loss_items[2]\n",
    "\n",
    "        total_loss = giou_loss + conf_loss + prob_loss\n",
    "        print(\" Total Loss \", total_loss)\n",
    "\n",
    "        gradients = tape.gradient(total_loss, yolo.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, yolo.trainable_variables))\n",
    "\n",
    "        # update learning rate\n",
    "        # about warmup: https://arxiv.org/pdf/1812.01187.pdf&usg=ALkJrhglKOPDjNt6SHGbphTHyMcT0cuMJg\n",
    "        global_steps.assign_add(1)\n",
    "        if global_steps < warmup_steps:# and not TRAIN_TRANSFER:\n",
    "            lr = global_steps / warmup_steps * TRAIN_LR_INIT\n",
    "        else:\n",
    "            lr = TRAIN_LR_END + 0.5 * (TRAIN_LR_INIT - TRAIN_LR_END)*(\n",
    "                (1 + tf.cos((global_steps - warmup_steps) / (total_steps - warmup_steps) * np.pi)))\n",
    "        optimizer.lr.assign(lr.numpy())\n",
    "\n",
    "#         # writing summary data\n",
    "#         with writer.as_default():\n",
    "#             tf.summary.scalar(\"lr\", optimizer.lr, step=global_steps)\n",
    "#             tf.summary.scalar(\"loss/total_loss\", total_loss, step=global_steps)\n",
    "#             tf.summary.scalar(\"loss/giou_loss\", giou_loss, step=global_steps)\n",
    "#             tf.summary.scalar(\"loss/conf_loss\", conf_loss, step=global_steps)\n",
    "#             tf.summary.scalar(\"loss/prob_loss\", prob_loss, step=global_steps)\n",
    "#         writer.flush()\n",
    "\n",
    "    return global_steps.numpy(), optimizer.lr.numpy(), giou_loss.numpy(), conf_loss.numpy(), prob_loss.numpy(), total_loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1,
     11,
     26,
     33,
     39
    ]
   },
   "outputs": [],
   "source": [
    "best_val_loss = 1000 # should be large at start\n",
    "for epoch in range(TRAIN_EPOCHS):\n",
    "    for image_data, target in trainset:\n",
    "        results = train_step(image_data, target)\n",
    "        print(\" ****  \")\n",
    "        cur_step = results[0]%steps_per_epoch\n",
    "        print(\"epoch:{:2.0f} step:{:5.0f}/{}, lr:{:.6f}, giou_loss:{:7.2f}, conf_loss:{:7.2f}, prob_loss:{:7.2f}, total_loss:{:7.2f}\"\n",
    "              .format(epoch, cur_step, steps_per_epoch, results[1], results[2], results[3], results[4], results[5]))\n",
    "        break\n",
    "#     break\n",
    "    \n",
    "    if len(testset) == 0:\n",
    "        print(\"configure TEST options to validate model\")\n",
    "        yolo.save_weights(os.path.join(TRAIN_CHECKPOINTS_FOLDER, TRAIN_MODEL_NAME))\n",
    "        continue\n",
    "    print(\" Validation \")\n",
    "    count, giou_val, conf_val, prob_val, total_val = 0., 0, 0, 0, 0\n",
    "    for image_data, target in testset:\n",
    "        print(\" Running val \")\n",
    "        results = validate_step(image_data, target)\n",
    "        count += 1\n",
    "        giou_val += results[0]\n",
    "        conf_val += results[1]\n",
    "        prob_val += results[2]\n",
    "        total_val += results[3]\n",
    "    # writing validate summary data\n",
    "    with validate_writer.as_default():\n",
    "        tf.summary.scalar(\"validate_loss/total_val\", total_val/count, step=epoch)\n",
    "        tf.summary.scalar(\"validate_loss/giou_val\", giou_val/count, step=epoch)\n",
    "        tf.summary.scalar(\"validate_loss/conf_val\", conf_val/count, step=epoch)\n",
    "        tf.summary.scalar(\"validate_loss/prob_val\", prob_val/count, step=epoch)\n",
    "    validate_writer.flush()\n",
    "\n",
    "    print(\"\\n\\ngiou_val_loss:{:7.2f}, conf_val_loss:{:7.2f}, prob_val_loss:{:7.2f}, total_val_loss:{:7.2f}\\n\\n\".\n",
    "          format(giou_val/count, conf_val/count, prob_val/count, total_val/count))\n",
    "\n",
    "    if TRAIN_SAVE_CHECKPOINT and not TRAIN_SAVE_BEST_ONLY:\n",
    "        save_directory = os.path.join(TRAIN_CHECKPOINTS_FOLDER, TRAIN_MODEL_NAME+\"_val_loss_{:7.2f}\".format(total_val/count))\n",
    "        yolo.save_weights(save_directory)\n",
    "    if TRAIN_SAVE_BEST_ONLY and best_val_loss>total_val/count:\n",
    "        save_directory = os.path.join(TRAIN_CHECKPOINTS_FOLDER, TRAIN_MODEL_NAME)\n",
    "        yolo.save_weights(save_directory)\n",
    "        best_val_loss = total_val/count\n",
    "    if not TRAIN_SAVE_BEST_ONLY and not TRAIN_SAVE_CHECKPOINT:\n",
    "        save_directory = os.path.join(TRAIN_CHECKPOINTS_FOLDER, TRAIN_MODEL_NAME)\n",
    "        yolo.save_weights(save_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import colorsys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "infer = YOLOV3(10, TRAIN=False)\n",
    "tert = np.random.rand(1,416,416,3).astype(np.float32)\n",
    "bert = infer(tert, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# infer.load_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     45,
     61,
     100,
     139
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def draw_bbox(image, bboxes, CLASSES=YOLO_COCO_CLASSES, show_label=True, show_confidence = True, Text_colors=(255,255,0), rectangle_colors='', tracking=False):   \n",
    "    NUM_CLASS = read_class_names(CLASSES)\n",
    "    num_classes = len(NUM_CLASS)\n",
    "    image_h, image_w, _ = image.shape\n",
    "    hsv_tuples = [(1.0 * x / num_classes, 1., 1.) for x in range(num_classes)]\n",
    "    #print(\"hsv_tuples\", hsv_tuples)\n",
    "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "    colors = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), colors))\n",
    "\n",
    "    random.seed(0)\n",
    "    random.shuffle(colors)\n",
    "    random.seed(None)\n",
    "\n",
    "    for i, bbox in enumerate(bboxes):\n",
    "        coor = np.array(bbox[:4], dtype=np.int32)\n",
    "        score = bbox[4]\n",
    "        class_ind = int(bbox[5])\n",
    "        bbox_color = rectangle_colors if rectangle_colors != '' else colors[class_ind]\n",
    "        bbox_thick = int(0.6 * (image_h + image_w) / 1000)\n",
    "        if bbox_thick < 1: bbox_thick = 1\n",
    "        fontScale = 0.75 * bbox_thick\n",
    "        (x1, y1), (x2, y2) = (coor[0], coor[1]), (coor[2], coor[3])\n",
    "\n",
    "        # put object rectangle\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), bbox_color, bbox_thick*2)\n",
    "\n",
    "        if show_label:\n",
    "            # get text label\n",
    "            score_str = \" {:.2f}\".format(score) if show_confidence else \"\"\n",
    "\n",
    "            if tracking: score_str = \" \"+str(score)\n",
    "\n",
    "            label = \"{}\".format(NUM_CLASS[class_ind]) + score_str\n",
    "\n",
    "            # get text size\n",
    "            (text_width, text_height), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
    "                                                                  fontScale, thickness=bbox_thick)\n",
    "            # put filled text rectangle\n",
    "            cv2.rectangle(image, (x1, y1), (x1 + text_width, y1 - text_height - baseline), bbox_color, thickness=cv2.FILLED)\n",
    "\n",
    "            # put text above rectangle\n",
    "            cv2.putText(image, label, (x1, y1-4), cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
    "                        fontScale, Text_colors, bbox_thick, lineType=cv2.LINE_AA)\n",
    "\n",
    "    return image\n",
    "def bboxes_iou(boxes1, boxes2):\n",
    "    boxes1 = np.array(boxes1)\n",
    "    boxes2 = np.array(boxes2)\n",
    "\n",
    "    boxes1_area = (boxes1[..., 2] - boxes1[..., 0]) * (boxes1[..., 3] - boxes1[..., 1])\n",
    "    boxes2_area = (boxes2[..., 2] - boxes2[..., 0]) * (boxes2[..., 3] - boxes2[..., 1])\n",
    "\n",
    "    left_up       = np.maximum(boxes1[..., :2], boxes2[..., :2])\n",
    "    right_down    = np.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
    "\n",
    "    inter_section = np.maximum(right_down - left_up, 0.0)\n",
    "    inter_area    = inter_section[..., 0] * inter_section[..., 1]\n",
    "    union_area    = boxes1_area + boxes2_area - inter_area\n",
    "    ious          = np.maximum(1.0 * inter_area / union_area, np.finfo(np.float32).eps)\n",
    "\n",
    "    return ious\n",
    "def nms(bboxes, iou_threshold, sigma=0.3, method='nms'):\n",
    "    \"\"\"\n",
    "    :param bboxes: (xmin, ymin, xmax, ymax, score, class)\n",
    "\n",
    "    Note: soft-nms, https://arxiv.org/pdf/1704.04503.pdf\n",
    "          https://github.com/bharatsingh430/soft-nms\n",
    "    \"\"\"\n",
    "    classes_in_img = list(set(bboxes[:, 5]))\n",
    "    best_bboxes = []\n",
    "\n",
    "    for cls in classes_in_img:\n",
    "        cls_mask = (bboxes[:, 5] == cls)\n",
    "        cls_bboxes = bboxes[cls_mask]\n",
    "        # Process 1: Determine whether the number of bounding boxes is greater than 0 \n",
    "        while len(cls_bboxes) > 0:\n",
    "            # Process 2: Select the bounding box with the highest score according to socre order A\n",
    "            max_ind = np.argmax(cls_bboxes[:, 4])\n",
    "            best_bbox = cls_bboxes[max_ind]\n",
    "            best_bboxes.append(best_bbox)\n",
    "            cls_bboxes = np.concatenate([cls_bboxes[: max_ind], cls_bboxes[max_ind + 1:]])\n",
    "            # Process 3: Calculate this bounding box A and\n",
    "            # Remain all iou of the bounding box and remove those bounding boxes whose iou value is higher than the threshold \n",
    "            iou = bboxes_iou(best_bbox[np.newaxis, :4], cls_bboxes[:, :4])\n",
    "            weight = np.ones((len(iou),), dtype=np.float32)\n",
    "\n",
    "            assert method in ['nms', 'soft-nms']\n",
    "\n",
    "            if method == 'nms':\n",
    "                iou_mask = iou > iou_threshold\n",
    "                weight[iou_mask] = 0.0\n",
    "\n",
    "            if method == 'soft-nms':\n",
    "                weight = np.exp(-(1.0 * iou ** 2 / sigma))\n",
    "\n",
    "            cls_bboxes[:, 4] = cls_bboxes[:, 4] * weight\n",
    "            score_mask = cls_bboxes[:, 4] > 0.\n",
    "            cls_bboxes = cls_bboxes[score_mask]\n",
    "\n",
    "    return best_bboxes\n",
    "def postprocess_boxes(pred_bbox, original_image, input_size, score_threshold):\n",
    "    valid_scale=[0, np.inf]\n",
    "    pred_bbox = np.array(pred_bbox)\n",
    "\n",
    "    pred_xywh = pred_bbox[:, 0:4]\n",
    "    pred_conf = pred_bbox[:, 4]\n",
    "    pred_prob = pred_bbox[:, 5:]\n",
    "\n",
    "    # 1. (x, y, w, h) --> (xmin, ymin, xmax, ymax)\n",
    "    pred_coor = np.concatenate([pred_xywh[:, :2] - pred_xywh[:, 2:] * 0.5,\n",
    "                                pred_xywh[:, :2] + pred_xywh[:, 2:] * 0.5], axis=-1)\n",
    "    # 2. (xmin, ymin, xmax, ymax) -> (xmin_org, ymin_org, xmax_org, ymax_org)\n",
    "    org_h, org_w = original_image.shape[:2]\n",
    "    resize_ratio = min(input_size / org_w, input_size / org_h)\n",
    "\n",
    "    dw = (input_size - resize_ratio * org_w) / 2\n",
    "    dh = (input_size - resize_ratio * org_h) / 2\n",
    "\n",
    "    pred_coor[:, 0::2] = 1.0 * (pred_coor[:, 0::2] - dw) / resize_ratio\n",
    "    pred_coor[:, 1::2] = 1.0 * (pred_coor[:, 1::2] - dh) / resize_ratio\n",
    "\n",
    "    # 3. clip some boxes those are out of range\n",
    "    pred_coor = np.concatenate([np.maximum(pred_coor[:, :2], [0, 0]),\n",
    "                                np.minimum(pred_coor[:, 2:], [org_w - 1, org_h - 1])], axis=-1)\n",
    "    invalid_mask = np.logical_or((pred_coor[:, 0] > pred_coor[:, 2]), (pred_coor[:, 1] > pred_coor[:, 3]))\n",
    "    pred_coor[invalid_mask] = 0\n",
    "\n",
    "    # 4. discard some invalid boxes\n",
    "    bboxes_scale = np.sqrt(np.multiply.reduce(pred_coor[:, 2:4] - pred_coor[:, 0:2], axis=-1))\n",
    "    scale_mask = np.logical_and((valid_scale[0] < bboxes_scale), (bboxes_scale < valid_scale[1]))\n",
    "\n",
    "    # 5. discard boxes with low scores\n",
    "    classes = np.argmax(pred_prob, axis=-1)\n",
    "    scores = pred_conf * pred_prob[np.arange(len(pred_coor)), classes]\n",
    "    score_mask = scores > score_threshold\n",
    "    mask = np.logical_and(scale_mask, score_mask)\n",
    "    coors, scores, classes = pred_coor[mask], scores[mask], classes[mask]\n",
    "\n",
    "    return np.concatenate([coors, scores[:, np.newaxis], classes[:, np.newaxis]], axis=-1)\n",
    "def image_preprocess(image, target_size, gt_boxes=None):\n",
    "    ih, iw    = target_size\n",
    "    h,  w, _  = image.shape\n",
    "\n",
    "    scale = min(iw/w, ih/h)\n",
    "    nw, nh  = int(scale * w), int(scale * h)\n",
    "    image_resized = cv2.resize(image, (nw, nh))\n",
    "\n",
    "    image_paded = np.full(shape=[ih, iw, 3], fill_value=128.0)\n",
    "    dw, dh = (iw - nw) // 2, (ih-nh) // 2\n",
    "    image_paded[dh:nh+dh, dw:nw+dw, :] = image_resized\n",
    "    image_paded = image_paded / 255.\n",
    "\n",
    "    if gt_boxes is None:\n",
    "        return image_paded\n",
    "\n",
    "    else:\n",
    "        gt_boxes[:, [0, 2]] = gt_boxes[:, [0, 2]] * scale + dw\n",
    "        gt_boxes[:, [1, 3]] = gt_boxes[:, [1, 3]] * scale + dh\n",
    "        return image_paded, gt_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def detect_image(YoloV3, image_path, output_path, input_size=416, show=False, CLASSES=TRAIN_CLASSES, score_threshold=0.3, iou_threshold=0.45, rectangle_colors=''):\n",
    "    original_image      = cv2.imread(image_path)\n",
    "    original_image      = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "    original_image      = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    image_data = image_preprocess(np.copy(original_image), [input_size, input_size])\n",
    "    image_data = tf.expand_dims(image_data, 0)\n",
    "\n",
    "    pred_bbox = YoloV3.predict(image_data)\n",
    "    pred_bbox = [tf.reshape(x, (-1, tf.shape(x)[-1])) for x in pred_bbox]\n",
    "    pred_bbox = tf.concat(pred_bbox, axis=0)\n",
    "    \n",
    "    bboxes = postprocess_boxes(pred_bbox, original_image, input_size, score_threshold)\n",
    "    bboxes = nms(bboxes, iou_threshold, method='nms')\n",
    "\n",
    "    image = draw_bbox(original_image, bboxes, CLASSES=CLASSES, rectangle_colors=rectangle_colors)\n",
    "\n",
    "    if output_path != '': cv2.imwrite(output_path, image)\n",
    "    if show:\n",
    "        # Show the image\n",
    "        cv2.imshow(\"predicted image\", image)\n",
    "        # Load and hold the image\n",
    "        cv2.waitKey(0)\n",
    "        # To close the window after the required kill value was provided\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "image_path   = \"Dataset/MNIST/mnist_train/000001.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "image = detect_image(yolo, image_path, '', input_size=416, show=False, rectangle_colors=(255,0,0))\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,15))\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from Dataset.MNIST.mnist_data import Dataset\n",
    "from Configs.mnist_config import *\n",
    "import shutil\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(gpus) > 0:\n",
    "    try: tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError: print(\"RuntimeError in tf.config.experimental.list_physical_devices('GPU')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     47,
     139
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def voc_ap(rec, prec):\n",
    "    \"\"\"\n",
    "    --- Official matlab code VOC2012---\n",
    "    mrec=[0 ; rec ; 1];\n",
    "    mpre=[0 ; prec ; 0];\n",
    "    for i=numel(mpre)-1:-1:1\n",
    "            mpre(i)=max(mpre(i),mpre(i+1));\n",
    "    end\n",
    "    i=find(mrec(2:end)~=mrec(1:end-1))+1;\n",
    "    ap=sum((mrec(i)-mrec(i-1)).*mpre(i));\n",
    "    \"\"\"\n",
    "    rec.insert(0, 0.0) # insert 0.0 at begining of list\n",
    "    rec.append(1.0) # insert 1.0 at end of list\n",
    "    mrec = rec[:]\n",
    "    prec.insert(0, 0.0) # insert 0.0 at begining of list\n",
    "    prec.append(0.0) # insert 0.0 at end of list\n",
    "    mpre = prec[:]\n",
    "    \"\"\"\n",
    "     This part makes the precision monotonically decreasing\n",
    "        (goes from the end to the beginning)\n",
    "        matlab:  for i=numel(mpre)-1:-1:1\n",
    "                                mpre(i)=max(mpre(i),mpre(i+1));\n",
    "    \"\"\"\n",
    "    # matlab indexes start in 1 but python in 0, so I have to do:\n",
    "    #   range(start=(len(mpre) - 2), end=0, step=-1)\n",
    "    # also the python function range excludes the end, resulting in:\n",
    "    #   range(start=(len(mpre) - 2), end=-1, step=-1)\n",
    "    for i in range(len(mpre)-2, -1, -1):\n",
    "        mpre[i] = max(mpre[i], mpre[i+1])\n",
    "    \"\"\"\n",
    "     This part creates a list of indexes where the recall changes\n",
    "        matlab:  i=find(mrec(2:end)~=mrec(1:end-1))+1;\n",
    "    \"\"\"\n",
    "    i_list = []\n",
    "    for i in range(1, len(mrec)):\n",
    "        if mrec[i] != mrec[i-1]:\n",
    "            i_list.append(i) # if it was matlab would be i + 1\n",
    "    \"\"\"\n",
    "     The Average Precision (AP) is the area under the curve\n",
    "        (numerical integration)\n",
    "        matlab: ap=sum((mrec(i)-mrec(i-1)).*mpre(i));\n",
    "    \"\"\"\n",
    "    ap = 0.0\n",
    "    for i in i_list:\n",
    "        ap += ((mrec[i]-mrec[i-1])*mpre[i])\n",
    "    return ap, mrec, mpre\n",
    "def get_mAP(model, dataset, score_threshold=0.25, iou_threshold=0.50, TEST_INPUT_SIZE=TEST_INPUT_SIZE):\n",
    "    MINOVERLAP = 0.5 # default value (defined in the PASCAL VOC2012 challenge)\n",
    "    NUM_CLASS = read_class_names(TRAIN_CLASSES)\n",
    "\n",
    "    ground_truth_dir_path = 'mAP/ground-truth'\n",
    "    if os.path.exists(ground_truth_dir_path): shutil.rmtree(ground_truth_dir_path)\n",
    "\n",
    "    if not os.path.exists('mAP'): os.mkdir('mAP')\n",
    "    os.mkdir(ground_truth_dir_path)\n",
    "\n",
    "    print(f'\\ncalculating mAP{int(iou_threshold*100)}...\\n')\n",
    "\n",
    "    gt_counter_per_class = {}\n",
    "    for index in range(dataset.num_samples):\n",
    "        ann_dataset = dataset.annotations[index]\n",
    "\n",
    "        original_image, bbox_data_gt = dataset.parse_annotation(ann_dataset, True)\n",
    "\n",
    "        if len(bbox_data_gt) == 0:\n",
    "            bboxes_gt = []\n",
    "            classes_gt = []\n",
    "        else:\n",
    "            bboxes_gt, classes_gt = bbox_data_gt[:, :4], bbox_data_gt[:, 4]\n",
    "        ground_truth_path = os.path.join(ground_truth_dir_path, str(index) + '.txt')\n",
    "        num_bbox_gt = len(bboxes_gt)\n",
    "\n",
    "        bounding_boxes = []\n",
    "        for i in range(num_bbox_gt):\n",
    "            class_name = NUM_CLASS[classes_gt[i]]\n",
    "            xmin, ymin, xmax, ymax = list(map(str, bboxes_gt[i]))\n",
    "            bbox = xmin + \" \" + ymin + \" \" + xmax + \" \" +ymax\n",
    "            bounding_boxes.append({\"class_name\":class_name, \"bbox\":bbox, \"used\":False})\n",
    "\n",
    "            # count that object\n",
    "            if class_name in gt_counter_per_class:\n",
    "                gt_counter_per_class[class_name] += 1\n",
    "            else:\n",
    "                # if class didn't exist yet\n",
    "                gt_counter_per_class[class_name] = 1\n",
    "            bbox_mess = ' '.join([class_name, xmin, ymin, xmax, ymax]) + '\\n'\n",
    "        with open(f'{ground_truth_dir_path}/{str(index)}_ground_truth.json', 'w') as outfile:\n",
    "            json.dump(bounding_boxes, outfile)\n",
    "\n",
    "    gt_classes = list(gt_counter_per_class.keys())\n",
    "    # sort the classes alphabetically\n",
    "    gt_classes = sorted(gt_classes)\n",
    "    n_classes = len(gt_classes)\n",
    "\n",
    "    times = []\n",
    "    json_pred = [[] for i in range(n_classes)]\n",
    "    for index in range(dataset.num_samples):\n",
    "        ann_dataset = dataset.annotations[index]\n",
    "\n",
    "        image_name = ann_dataset[0].split('/')[-1]\n",
    "        original_image, bbox_data_gt = dataset.parse_annotation(ann_dataset, True)\n",
    "        \n",
    "        image = image_preprocess(np.copy(original_image), [TEST_INPUT_SIZE, TEST_INPUT_SIZE])\n",
    "        image_data = tf.expand_dims(image, 0)\n",
    "\n",
    "        t1 = time.time()\n",
    "        pred_bbox = model.predict(image_data)\n",
    "        t2 = time.time()\n",
    "        times.append(t2-t1)\n",
    "        \n",
    "        pred_bbox = [tf.reshape(x, (-1, tf.shape(x)[-1])) for x in pred_bbox]\n",
    "        pred_bbox = tf.concat(pred_bbox, axis=0)\n",
    "\n",
    "        bboxes = postprocess_boxes(pred_bbox, original_image, TEST_INPUT_SIZE, score_threshold)\n",
    "        bboxes = nms(bboxes, iou_threshold, method='nms')\n",
    "\n",
    "        for bbox in bboxes:\n",
    "            coor = np.array(bbox[:4], dtype=np.int32)\n",
    "            score = bbox[4]\n",
    "            class_ind = int(bbox[5])\n",
    "            class_name = NUM_CLASS[class_ind]\n",
    "            score = '%.4f' % score\n",
    "            xmin, ymin, xmax, ymax = list(map(str, coor))\n",
    "            bbox = xmin + \" \" + ymin + \" \" + xmax + \" \" +ymax\n",
    "            json_pred[gt_classes.index(class_name)].append({\"confidence\": str(score), \"file_id\": str(index), \"bbox\": str(bbox)})\n",
    "\n",
    "    ms = sum(times)/len(times)*1000\n",
    "    fps = 1000 / ms\n",
    "\n",
    "    for class_name in gt_classes:\n",
    "        json_pred[gt_classes.index(class_name)].sort(key=lambda x:float(x['confidence']), reverse=True)\n",
    "        with open(f'{ground_truth_dir_path}/{class_name}_predictions.json', 'w') as outfile:\n",
    "            json.dump(json_pred[gt_classes.index(class_name)], outfile)\n",
    "\n",
    "    # Calculate the AP for each class\n",
    "    sum_AP = 0.0\n",
    "    ap_dictionary = {}\n",
    "    # open file to store the results\n",
    "    with open(\"mAP/results.txt\", 'w') as results_file:\n",
    "        results_file.write(\"# AP and precision/recall per class\\n\")\n",
    "        count_true_positives = {}\n",
    "        for class_index, class_name in enumerate(gt_classes):\n",
    "            count_true_positives[class_name] = 0\n",
    "            # Load predictions of that class\n",
    "            predictions_file = f'{ground_truth_dir_path}/{class_name}_predictions.json'\n",
    "            predictions_data = json.load(open(predictions_file))\n",
    "\n",
    "            # Assign predictions to ground truth objects\n",
    "            nd = len(predictions_data)\n",
    "            tp = [0] * nd # creates an array of zeros of size nd\n",
    "            fp = [0] * nd\n",
    "            for idx, prediction in enumerate(predictions_data):\n",
    "                file_id = prediction[\"file_id\"]\n",
    "                # assign prediction to ground truth object if any\n",
    "                #   open ground-truth with that file_id\n",
    "                gt_file = f'{ground_truth_dir_path}/{str(file_id)}_ground_truth.json'\n",
    "                ground_truth_data = json.load(open(gt_file))\n",
    "                ovmax = -1\n",
    "                gt_match = -1\n",
    "                # load prediction bounding-box\n",
    "                bb = [ float(x) for x in prediction[\"bbox\"].split() ] # bounding box of prediction\n",
    "                for obj in ground_truth_data:\n",
    "                    # look for a class_name match\n",
    "                    if obj[\"class_name\"] == class_name:\n",
    "                        bbgt = [ float(x) for x in obj[\"bbox\"].split() ] # bounding box of ground truth\n",
    "                        bi = [max(bb[0],bbgt[0]), max(bb[1],bbgt[1]), min(bb[2],bbgt[2]), min(bb[3],bbgt[3])]\n",
    "                        iw = bi[2] - bi[0] + 1\n",
    "                        ih = bi[3] - bi[1] + 1\n",
    "                        if iw > 0 and ih > 0:\n",
    "                            # compute overlap (IoU) = area of intersection / area of union\n",
    "                            ua = (bb[2] - bb[0] + 1) * (bb[3] - bb[1] + 1) + (bbgt[2] - bbgt[0]\n",
    "                                            + 1) * (bbgt[3] - bbgt[1] + 1) - iw * ih\n",
    "                            ov = iw * ih / ua\n",
    "                            if ov > ovmax:\n",
    "                                ovmax = ov\n",
    "                                gt_match = obj\n",
    "\n",
    "                # assign prediction as true positive/don't care/false positive\n",
    "                if ovmax >= MINOVERLAP:# if ovmax > minimum overlap\n",
    "                    if not bool(gt_match[\"used\"]):\n",
    "                        # true positive\n",
    "                        tp[idx] = 1\n",
    "                        gt_match[\"used\"] = True\n",
    "                        count_true_positives[class_name] += 1\n",
    "                        # update the \".json\" file\n",
    "                        with open(gt_file, 'w') as f:\n",
    "                            f.write(json.dumps(ground_truth_data))\n",
    "                    else:\n",
    "                        # false positive (multiple detection)\n",
    "                        fp[idx] = 1\n",
    "                else:\n",
    "                    # false positive\n",
    "                    fp[idx] = 1\n",
    "\n",
    "            # compute precision/recall\n",
    "            cumsum = 0\n",
    "            for idx, val in enumerate(fp):\n",
    "                fp[idx] += cumsum\n",
    "                cumsum += val\n",
    "            cumsum = 0\n",
    "            for idx, val in enumerate(tp):\n",
    "                tp[idx] += cumsum\n",
    "                cumsum += val\n",
    "            #print(tp)\n",
    "            rec = tp[:]\n",
    "            for idx, val in enumerate(tp):\n",
    "                rec[idx] = float(tp[idx]) / gt_counter_per_class[class_name]\n",
    "            #print(rec)\n",
    "            prec = tp[:]\n",
    "            for idx, val in enumerate(tp):\n",
    "                prec[idx] = float(tp[idx]) / (fp[idx] + tp[idx])\n",
    "            #print(prec)\n",
    "\n",
    "            ap, mrec, mprec = voc_ap(rec, prec)\n",
    "            sum_AP += ap\n",
    "            text = \"{0:.3f}%\".format(ap*100) + \" = \" + class_name + \" AP  \" #class_name + \" AP = {0:.2f}%\".format(ap*100)\n",
    "\n",
    "            rounded_prec = [ '%.3f' % elem for elem in prec ]\n",
    "            rounded_rec = [ '%.3f' % elem for elem in rec ]\n",
    "            # Write to results.txt\n",
    "            results_file.write(text + \"\\n Precision: \" + str(rounded_prec) + \"\\n Recall   :\" + str(rounded_rec) + \"\\n\\n\")\n",
    "\n",
    "            print(text)\n",
    "            ap_dictionary[class_name] = ap\n",
    "\n",
    "        results_file.write(\"\\n# mAP of all classes\\n\")\n",
    "        mAP = sum_AP / n_classes\n",
    "\n",
    "        text = \"mAP = {:.3f}%, {:.2f} FPS\".format(mAP*100, fps)\n",
    "        results_file.write(text + \"\\n\")\n",
    "        print(text)\n",
    "        \n",
    "        return mAP*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "yolo = YOLOV3(10, TRAIN=False)\n",
    "tert = np.random.rand(1,416,416,3).astype(np.float32)\n",
    "bert = yolo(tert, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "yolo.load_weights('MNIST_WEIGHTS/check6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from Dataset.MNIST.mnist_data import Dataset\n",
    "testset = Dataset('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "get_mAP(yolo, testset, score_threshold=TEST_SCORE_THRESHOLD, iou_threshold=TEST_IOU_THRESHOLD, TEST_INPUT_SIZE=YOLO_INPUT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Yolo3 Mobilenet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# %cd ..\n",
    "# !git clone https://github.com/fsx950223/mobilenetv2-yolov3.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%cd mobilenetv2-yolov3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.layers import UpSampling2D, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import BatchNormalization, Input, Lambda, Conv2D\n",
    "from tensorflow.keras.layers import LeakyReLU, UpSampling2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from functools import wraps, reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def compose(*funcs):\n",
    "    \"\"\"Compose arbitrarily many functions, evaluated left to right.\n",
    "    Reference: https://mathieularose.com/function-composition-in-python/\n",
    "    \"\"\"\n",
    "    # return lambda x: reduce(lambda v, f: f(v), funcs, x)\n",
    "    if funcs:\n",
    "        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)\n",
    "    else:\n",
    "        raise ValueError('Composition of empty sequence not supported.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def yolo3_mobilenetv2_body(inputs, num_anchors, num_classes, alpha=1.0):\n",
    "    \"\"\"Create YOLO_V3 MobileNetV2 model CNN body in Keras.\"\"\"\n",
    "    mobilenetv2 = MobileNetV2(input_tensor=inputs, weights='imagenet', include_top=False, alpha=alpha)\n",
    "    print('backbone layers number: {}'.format(len(mobilenetv2.layers)))\n",
    "\n",
    "    # input: 416 x 416 x 3\n",
    "    # out_relu: 13 x 13 x 1280\n",
    "    # block_13_expand_relu: 26 x 26 x (576*alpha)\n",
    "    # block_6_expand_relu: 52 x 52 x (192*alpha)\n",
    "\n",
    "    # f1 :13 x 13 x 1280\n",
    "    f1 = mobilenetv2.get_layer('out_relu').output\n",
    "    # f2: 26 x 26 x (576*alpha)\n",
    "    f2 = mobilenetv2.get_layer('block_13_expand_relu').output\n",
    "    # f3 : 52 x 52 x (192*alpha)\n",
    "    f3 = mobilenetv2.get_layer('block_6_expand_relu').output\n",
    "\n",
    "    f1_channel_num = int(1280*alpha)\n",
    "    f2_channel_num = int(576*alpha)\n",
    "    f3_channel_num = int(192*alpha)\n",
    "    #f1_channel_num = 1024\n",
    "    #f2_channel_num = 512\n",
    "    #f3_channel_num = 256\n",
    "\n",
    "    y1, y2, y3 = yolo3_predictions((f1, f2, f3), (f1_channel_num, f2_channel_num, f3_channel_num), num_anchors, num_classes)\n",
    "\n",
    "    return Model(inputs = inputs, outputs=[y1,y2,y3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def DarknetConv2D(*args, **kwargs):\n",
    "    \"\"\"Wrapper to set Darknet parameters for Conv2D.\"\"\"\n",
    "    darknet_conv_kwargs = {'kernel_regularizer': l2(5e-4)}\n",
    "    darknet_conv_kwargs['padding'] = 'valid' if kwargs.get('strides')==(2,2) else 'same'\n",
    "    darknet_conv_kwargs.update(kwargs)\n",
    "    return Conv2D(*args, **darknet_conv_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def DarknetConv2D_BN_Leaky(*args, **kwargs):\n",
    "    \"\"\"Darknet Convolution2D followed by BatchNormalization and LeakyReLU.\"\"\"\n",
    "    no_bias_kwargs = {'use_bias': False}\n",
    "    no_bias_kwargs.update(kwargs)\n",
    "    return compose(\n",
    "        DarknetConv2D(*args, **no_bias_kwargs),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_last_layers(x, num_filters, out_filters, predict_filters=None, predict_id='1'):\n",
    "    '''6 Conv2D_BN_Leaky layers followed by a Conv2D_linear layer'''\n",
    "    x = compose(\n",
    "            DarknetConv2D_BN_Leaky(num_filters, (1,1)),\n",
    "            DarknetConv2D_BN_Leaky(num_filters*2, (3,3)),\n",
    "            DarknetConv2D_BN_Leaky(num_filters, (1,1)),\n",
    "            DarknetConv2D_BN_Leaky(num_filters*2, (3,3)),\n",
    "            DarknetConv2D_BN_Leaky(num_filters, (1,1)))(x)\n",
    "\n",
    "    if predict_filters is None:\n",
    "        predict_filters = num_filters*2\n",
    "    y = compose(\n",
    "            DarknetConv2D_BN_Leaky(predict_filters, (3,3)),\n",
    "            DarknetConv2D(out_filters, (1,1), name='predict_conv_' + predict_id))(x)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def yolo3_predictions(feature_maps, feature_channel_nums, num_anchors, num_classes, use_spp=False):\n",
    "    f1, f2, f3 = feature_maps\n",
    "    f1_channel_num, f2_channel_num, f3_channel_num = feature_channel_nums\n",
    "\n",
    "    #feature map 1 head & output (13x13 for 416 input)\n",
    "    if use_spp:\n",
    "        x, y1 = make_spp_last_layers(f1, f1_channel_num//2, num_anchors * (num_classes + 5), predict_id='1')\n",
    "    else:\n",
    "        x, y1 = make_last_layers(f1, f1_channel_num//2, num_anchors * (num_classes + 5), predict_id='1')\n",
    "\n",
    "    #upsample fpn merge for feature map 1 & 2\n",
    "    x = compose(\n",
    "            DarknetConv2D_BN_Leaky(f2_channel_num//2, (1,1)),\n",
    "            UpSampling2D(2))(x)\n",
    "    x = Concatenate()([x,f2])\n",
    "\n",
    "    #feature map 2 head & output (26x26 for 416 input)\n",
    "    x, y2 = make_last_layers(x, f2_channel_num//2, num_anchors*(num_classes+5), predict_id='2')\n",
    "\n",
    "    #upsample fpn merge for feature map 2 & 3\n",
    "    x = compose(\n",
    "            DarknetConv2D_BN_Leaky(f3_channel_num//2, (1,1)),\n",
    "            UpSampling2D(2))(x)\n",
    "    x = Concatenate()([x, f3])\n",
    "\n",
    "    #feature map 3 head & output (52x52 for 416 input)\n",
    "    x, y3 = make_last_layers(x, f3_channel_num//2, num_anchors*(num_classes+5), predict_id='3')\n",
    "\n",
    "    return y1, y2, y3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "input_shape =  (416 ,416 , 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "input_tensor = Input(shape=input_shape, name='image_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = yolo3_mobilenetv2_body(input_tensor, 9, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
